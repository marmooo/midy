import { parseMidi } from "https://cdn.jsdelivr.net/npm/midi-file@1.2.4/+esm";
import {
  parse,
  SoundFont,
} from "https://cdn.jsdelivr.net/npm/@marmooo/soundfont-parser@0.0.1/+esm";

export class Midy {
  ticksPerBeat = 120;
  totalTime = 0;
  reverbFactor = 0.1;
  masterFineTuning = 0;
  masterCoarseTuning = 0;
  mono = false; // CC#124, CC#125
  omni = false; // CC#126, CC#127
  noteCheckInterval = 0.1;
  lookAhead = 1;
  startDelay = 0.1;
  startTime = 0;
  resumeTime = 0;
  soundFonts = [];
  soundFontTable = this.initSoundFontTable();
  isPlaying = false;
  isPausing = false;
  isPaused = false;
  isStopping = false;
  isSeeking = false;
  timeline = [];
  instruments = [];
  notePromises = [];

  static channelSettings = {
    currentBufferSource: null,
    volume: 100 / 127,
    pan: 0,
    portamentoTime: 0,
    reverb: 0,
    chorus: 0,
    vibratoRate: 5,
    vibratoDepth: 0.5,
    vibratoDelay: 2.5,
    bank: 121 * 128,
    bankMSB: 121,
    bankLSB: 0,
    dataMSB: 0,
    dataLSB: 0,
    program: 0,
    pitchBend: 0,
    fineTuning: 0,
    coarseTuning: 0,
    modulationDepthRange: 0.5,
  };

  static effectSettings = {
    expression: 1,
    modulation: 0,
    sustainPedal: false,
    portamento: false,
    sostenutoPedal: false,
    softPedal: 0,
    rpnMSB: 127,
    rpnLSB: 127,
    channelPressure: 0,
    pitchBendRange: 2,
  };

  static controllerDestinationSettings = {
    pitchControl: 0,
    filterCutoffControl: 0,
    amplitudeControl: 1,
    lfoPitchDepth: 0,
    lfoFilterDepth: 0,
    lfoAmplitudeDepth: 0,
  };

  constructor(audioContext) {
    this.audioContext = audioContext;
    this.masterGain = new GainNode(audioContext);
    this.masterGain.connect(audioContext.destination);
    this.channels = this.createChannels(audioContext);
    this.GM2SystemOn();
  }

  initSoundFontTable() {
    const table = new Array(128);
    for (let i = 0; i < 128; i++) {
      table[i] = new Map();
    }
    return table;
  }

  addSoundFont(soundFont) {
    const index = this.soundFonts.length;
    this.soundFonts.push(soundFont);
    soundFont.parsed.presetHeaders.forEach((presetHeader) => {
      if (!presetHeader.presetName.startsWith("\u0000")) { // TODO: Only SF3 generated by PolyPone?
        const banks = this.soundFontTable[presetHeader.preset];
        banks.set(presetHeader.bank, index);
      }
    });
  }

  async loadSoundFont(soundFontUrl) {
    const response = await fetch(soundFontUrl);
    const arrayBuffer = await response.arrayBuffer();
    const parsed = parse(new Uint8Array(arrayBuffer));
    const soundFont = new SoundFont(parsed);
    this.addSoundFont(soundFont);
  }

  async loadMIDI(midiUrl) {
    const response = await fetch(midiUrl);
    const arrayBuffer = await response.arrayBuffer();
    const midi = parseMidi(new Uint8Array(arrayBuffer));
    this.ticksPerBeat = midi.header.ticksPerBeat;
    const midiData = this.extractMidiData(midi);
    this.instruments = midiData.instruments;
    this.timeline = midiData.timeline;
    this.totalTime = this.calcTotalTime();
  }

  setChannelAudioNodes(audioContext) {
    const gainNode = new GainNode(audioContext, {
      gain: Midy.channelSettings.volume,
    });
    const pannerNode = new StereoPannerNode(audioContext, {
      pan: Midy.channelSettings.pan,
    });
    const modulationEffect = this.createModulationEffect(audioContext);
    const reverbEffect = this.createReverbEffect(audioContext);
    const chorusEffect = this.createChorusEffect(audioContext);
    modulationEffect.lfo.start();
    chorusEffect.lfo.start();
    reverbEffect.dryGain.connect(pannerNode);
    reverbEffect.wetGain.connect(pannerNode);
    pannerNode.connect(gainNode);
    gainNode.connect(this.masterGain);
    return {
      gainNode,
      pannerNode,
      modulationEffect,
      reverbEffect,
      chorusEffect,
    };
  }

  createChannels(audioContext) {
    const channels = Array.from({ length: 16 }, () => {
      return {
        ...Midy.channelSettings,
        ...Midy.effectSettings,
        ...this.setChannelAudioNodes(audioContext),
        scheduledNotes: new Map(),
        sostenutoNotes: new Map(),
        polyphonicKeyPressure: {
          ...Midy.controllerDestinationSettings,
        },
        channelPressure: {
          ...Midy.controllerDestinationSettings,
        },
      };
    });
    return channels;
  }

  async createNoteBuffer(noteInfo, isSF3) {
    const sampleEnd = noteInfo.sample.length + noteInfo.end;
    if (isSF3) {
      const sample = new Uint8Array(noteInfo.sample.length);
      sample.set(noteInfo.sample);
      const audioBuffer = await this.audioContext.decodeAudioData(
        sample.buffer,
      );
      for (let channel = 0; channel < audioBuffer.numberOfChannels; channel++) {
        const channelData = audioBuffer.getChannelData(channel);
        channelData.set(channelData.subarray(0, sampleEnd));
      }
      return audioBuffer;
    } else {
      const sample = noteInfo.sample.subarray(0, sampleEnd);
      const floatSample = this.convertToFloat32Array(sample);
      const audioBuffer = new AudioBuffer({
        numberOfChannels: 1,
        length: sample.length,
        sampleRate: noteInfo.sampleRate,
      });
      const channelData = audioBuffer.getChannelData(0);
      channelData.set(floatSample);
      return audioBuffer;
    }
  }

  async createNoteBufferNode(noteInfo, isSF3) {
    const bufferSource = new AudioBufferSourceNode(this.audioContext);
    const audioBuffer = await this.createNoteBuffer(noteInfo, isSF3);
    bufferSource.buffer = audioBuffer;
    bufferSource.loop = noteInfo.sampleModes % 2 !== 0;
    if (bufferSource.loop) {
      bufferSource.loopStart = noteInfo.loopStart / noteInfo.sampleRate;
      bufferSource.loopEnd = noteInfo.loopEnd / noteInfo.sampleRate;
    }
    return bufferSource;
  }

  convertToFloat32Array(uint8Array) {
    const int16Array = new Int16Array(uint8Array.buffer);
    const float32Array = new Float32Array(int16Array.length);
    for (let i = 0; i < int16Array.length; i++) {
      float32Array[i] = int16Array[i] / 32768;
    }
    return float32Array;
  }

  async scheduleTimelineEvents(t, offset, queueIndex) {
    while (queueIndex < this.timeline.length) {
      const event = this.timeline[queueIndex];
      if (event.startTime > t + this.lookAhead) break;
      switch (event.type) {
        case "noteOn":
          if (event.velocity !== 0) {
            await this.scheduleNoteOn(
              event.channel,
              event.noteNumber,
              event.velocity,
              event.startTime + this.startDelay - offset,
            );
            break;
          }
          /* falls through */
        case "noteOff": {
          const notePromise = this.scheduleNoteRelease(
            this.omni ? 0 : event.channel,
            event.noteNumber,
            event.velocity,
            event.startTime + this.startDelay - offset,
          );
          if (notePromise) {
            this.notePromises.push(notePromise);
          }
          break;
        }
        case "noteAftertouch":
          this.handlePolyphonicKeyPressure(
            event.channel,
            event.noteNumber,
            event.amount,
          );
          break;
        case "controller":
          this.handleControlChange(
            this.omni ? 0 : event.channel,
            event.controllerType,
            event.value,
          );
          break;
        case "programChange":
          this.handleProgramChange(event.channel, event.programNumber);
          break;
        case "channelAftertouch":
          this.handleChannelPressure(event.channel, event.amount);
          break;
        case "pitchBend":
          this.handlePitchBend(event.channel, event.value);
          break;
        case "sysEx":
          this.handleSysEx(event.data);
      }
      queueIndex++;
    }
    return queueIndex;
  }

  getQueueIndex(second) {
    for (let i = 0; i < this.timeline.length; i++) {
      if (second <= this.timeline[i].startTime) {
        return i;
      }
    }
    return 0;
  }

  playNotes() {
    return new Promise((resolve) => {
      this.isPlaying = true;
      this.isPaused = false;
      this.startTime = this.audioContext.currentTime;
      let queueIndex = this.getQueueIndex(this.resumeTime);
      let offset = this.resumeTime - this.startTime;
      this.notePromises = [];
      const schedulePlayback = async () => {
        if (queueIndex >= this.timeline.length) {
          await Promise.all(this.notePromises);
          this.notePromises = [];
          resolve();
          return;
        }
        const t = this.audioContext.currentTime + offset;
        queueIndex = await this.scheduleTimelineEvents(t, offset, queueIndex);
        if (this.isPausing) {
          await this.stopNotes();
          this.notePromises = [];
          resolve();
          this.isPausing = false;
          this.isPaused = true;
          return;
        } else if (this.isStopping) {
          await this.stopNotes();
          this.notePromises = [];
          resolve();
          this.isStopping = false;
          this.isPaused = false;
          return;
        } else if (this.isSeeking) {
          this.stopNotes();
          this.startTime = this.audioContext.currentTime;
          queueIndex = this.getQueueIndex(this.resumeTime);
          offset = this.resumeTime - this.startTime;
          this.isSeeking = false;
          await schedulePlayback();
        } else {
          const now = this.audioContext.currentTime;
          const waitTime = now + this.noteCheckInterval;
          await this.scheduleTask(() => {}, waitTime);
          await schedulePlayback();
        }
      };
      schedulePlayback();
    });
  }

  ticksToSecond(ticks, secondsPerBeat) {
    return ticks * secondsPerBeat / this.ticksPerBeat;
  }

  secondToTicks(second, secondsPerBeat) {
    return second * this.ticksPerBeat / secondsPerBeat;
  }

  extractMidiData(midi) {
    const instruments = new Set();
    const timeline = [];
    const tmpChannels = new Array(16);
    for (let i = 0; i < tmpChannels.length; i++) {
      tmpChannels[i] = {
        durationTicks: new Map(),
        programNumber: -1,
        bankMSB: this.channels[i].bankMSB,
        bankLSB: this.channels[i].bankLSB,
      };
    }
    midi.tracks.forEach((track) => {
      let currentTicks = 0;
      track.forEach((event) => {
        currentTicks += event.deltaTime;
        event.ticks = currentTicks;
        switch (event.type) {
          case "noteOn": {
            const channel = tmpChannels[event.channel];
            if (channel.programNumber < 0) {
              channel.programNumber = event.programNumber;
              switch (channel.bankMSB) {
                case 120:
                  instruments.add(`128:0`);
                  break;
                case 121:
                  instruments.add(`${channel.bankLSB}:0`);
                  break;
                default: {
                  const bankNumber = channel.bankMSB * 128 + channel.bankLSB;
                  instruments.add(`${bankNumber}:0`);
                }
              }
              channel.programNumber = 0;
            }
            channel.durationTicks.set(event.noteNumber, {
              ticks: event.ticks,
              noteOn: event,
            });
            break;
          }
          case "noteOff": {
            const { ticks, noteOn } = tmpChannels[event.channel].durationTicks
              .get(event.noteNumber);
            noteOn.durationTicks = event.ticks - ticks;
            break;
          }
          case "controller":
            switch (event.controllerType) {
              case 0:
                tmpChannels[event.channel].bankMSB = event.value;
                break;
              case 32:
                tmpChannels[event.channel].bankLSB = event.value;
                break;
            }
            break;
          case "programChange": {
            const channel = tmpChannels[event.channel];
            channel.programNumber = event.programNumber;
            switch (channel.bankMSB) {
              case 120:
                instruments.add(`128:${channel.programNumber}`);
                break;
              case 121:
                instruments.add(`${channel.bankLSB}:${channel.programNumber}`);
                break;
              default: {
                const bankNumber = channel.bankMSB * 128 + channel.bankLSB;
                instruments.add(`${bankNumber}:${channel.programNumber}`);
              }
            }
          }
        }
        delete event.deltaTime;
        timeline.push(event);
      });
    });
    const priority = {
      setTempo: 0,
      controller: 1,
    };
    timeline.sort((a, b) => {
      if (a.ticks !== b.ticks) return a.ticks - b.ticks;
      return (priority[a.type] || 2) - (priority[b.type] || 2);
    });
    let prevTempoTime = 0;
    let prevTempoTicks = 0;
    let secondsPerBeat = 0.5;
    for (let i = 0; i < timeline.length; i++) {
      const event = timeline[i];
      const timeFromPrevTempo = this.ticksToSecond(
        event.ticks - prevTempoTicks,
        secondsPerBeat,
      );
      event.startTime = prevTempoTime + timeFromPrevTempo;
      if (event.type === "setTempo") {
        prevTempoTime += this.ticksToSecond(
          event.ticks - prevTempoTicks,
          secondsPerBeat,
        );
        secondsPerBeat = event.microsecondsPerBeat / 1000000;
        prevTempoTicks = event.ticks;
      }
    }
    return { instruments, timeline };
  }

  stopNotes() {
    const now = this.audioContext.currentTime;
    const velocity = 0;
    const stopPedal = true;
    this.channels.forEach((channel, channelNumber) => {
      channel.scheduledNotes.forEach((scheduledNotes) => {
        scheduledNotes.forEach((scheduledNote) => {
          if (scheduledNote) {
            const promise = this.scheduleNoteRelease(
              channelNumber,
              scheduledNote.noteNumber,
              velocity,
              now,
              stopPedal,
            );
            this.notePromises.push(promise);
          }
        });
      });
      channel.scheduledNotes.clear();
    });
    return Promise.all(this.notePromises);
  }

  async start() {
    if (this.isPlaying || this.isPaused) return;
    this.resumeTime = 0;
    await this.playNotes();
    this.isPlaying = false;
  }

  stop() {
    if (!this.isPlaying) return;
    this.isStopping = true;
  }

  pause() {
    if (!this.isPlaying || this.isPaused) return;
    const now = this.audioContext.currentTime;
    this.resumeTime += now - this.startTime - this.startDelay;
    this.isPausing = true;
  }

  async resume() {
    if (!this.isPaused) return;
    await this.playNotes();
    this.isPlaying = false;
  }

  seekTo(second) {
    this.resumeTime = second;
    if (this.isPlaying) {
      this.isSeeking = true;
    }
  }

  calcTotalTime() {
    let totalTime = 0;
    for (let i = 0; i < this.timeline.length; i++) {
      const event = this.timeline[i];
      if (totalTime < event.startTime) totalTime = event.startTime;
    }
    return totalTime;
  }

  currentTime() {
    const now = this.audioContext.currentTime;
    return this.resumeTime + now - this.startTime - this.startDelay;
  }

  getActiveNotes(channel) {
    const activeNotes = new Map();
    channel.scheduledNotes.forEach((scheduledNotes) => {
      const activeNote = this.getActiveChannelNotes(scheduledNotes);
      if (activeNote) {
        activeNotes.set(activeNote.noteNumber, activeNote);
      }
    });
    return activeNotes;
  }

  getActiveChannelNotes(scheduledNotes) {
    for (let i = 0; i < scheduledNotes; i++) {
      const scheduledNote = scheduledNotes[i];
      if (scheduledNote) return scheduledNote;
    }
  }

  createModulationEffect(audioContext) {
    const lfo = new OscillatorNode(audioContext, {
      frequency: 5,
    });
    return {
      lfo,
    };
  }

  createReverbEffect(audioContext, options = {}) {
    const {
      decay = 0.8,
      preDecay = 0,
    } = options;
    const sampleRate = audioContext.sampleRate;
    const length = sampleRate * decay;
    const impulse = new AudioBuffer({
      numberOfChannels: 2,
      length,
      sampleRate,
    });
    const preDecayLength = Math.min(sampleRate * preDecay, length);
    for (let channel = 0; channel < impulse.numberOfChannels; channel++) {
      const channelData = impulse.getChannelData(channel);
      for (let i = 0; i < preDecayLength; i++) {
        channelData[i] = Math.random() * 2 - 1;
      }
      for (let i = preDecayLength; i < length; i++) {
        const attenuation = Math.exp(
          -(i - preDecayLength) / sampleRate / decay,
        );
        channelData[i] = (Math.random() * 2 - 1) * attenuation;
      }
    }
    const convolverNode = new ConvolverNode(audioContext, {
      buffer: impulse,
    });
    const dryGain = new GainNode(audioContext);
    const wetGain = new GainNode(audioContext);
    convolverNode.connect(wetGain);
    return {
      convolverNode,
      dryGain,
      wetGain,
    };
  }

  createChorusEffect(audioContext, options = {}) {
    const {
      chorusCount = 2,
      chorusRate = 0.6,
      chorusDepth = 0.15,
      delay = 0.01,
      variance = delay * 0.1,
    } = options;

    const lfo = new OscillatorNode(audioContext, {
      frequency: chorusRate,
    });
    const lfoGain = new GainNode(audioContext, {
      gain: chorusDepth,
    });

    const chorusGains = [];
    const delayNodes = [];
    const baseGain = 1 / chorusCount;

    for (let i = 0; i < chorusCount; i++) {
      const randomDelayFactor = (Math.random() - 0.5) * variance;
      const delayTime = (i + 1) * delay + randomDelayFactor;
      const delayNode = new DelayNode(audioContext, {
        maxDelayTime: delayTime,
      });
      delayNodes.push(delayNode);

      const chorusGain = new GainNode(audioContext, {
        gain: baseGain,
      });
      chorusGains.push(chorusGain);

      lfo.connect(lfoGain);
      lfoGain.connect(delayNode.delayTime);
      delayNode.connect(chorusGain);
    }
    return {
      lfo,
      lfoGain,
      delayNodes,
      chorusGains,
    };
  }

  connectNoteEffects(channel, gainNode) {
    if (channel.reverb === 0) {
      if (channel.chorus === 0) { // no effect
        gainNode.connect(channel.pannerNode);
      } else { // chorus
        channel.chorusEffect.delayNodes.forEach((delayNode) => {
          gainNode.connect(delayNode);
        });
        channel.chorusEffect.chorusGains.forEach((chorusGain) => {
          chorusGain.connect(channel.pannerNode);
        });
      }
    } else {
      if (channel.chorus === 0) { // reverb
        gainNode.connect(channel.reverbEffect.convolverNode);
        gainNode.connect(channel.reverbEffect.dryGain);
      } else { // reverb + chorus
        gainNode.connect(channel.reverbEffect.convolverNode);
        gainNode.connect(channel.reverbEffect.dryGain);
        channel.chorusEffect.delayNodes.forEach((delayNode) => {
          gainNode.connect(delayNode);
        });
        channel.chorusEffect.chorusGains.forEach((chorusGain) => {
          chorusGain.connect(channel.reverbEffect.convolverNode);
        });
      }
    }
  }

  cbToRatio(cb) {
    return Math.pow(10, cb / 200);
  }

  centToHz(cent) {
    return 8.176 * Math.pow(2, cent / 1200);
  }

  calcSemitoneOffset(channel) {
    const masterTuning = this.masterCoarseTuning + this.masterFineTuning;
    const channelTuning = channel.coarseTuning + channel.fineTuning;
    const tuning = masterTuning + channelTuning;
    return channel.pitchBend * channel.pitchBendRange + tuning;
  }

  calcPlaybackRate(noteInfo, noteNumber, semitoneOffset) {
    return noteInfo.playbackRate(noteNumber) * Math.pow(2, semitoneOffset / 12);
  }

  async createNoteAudioChain(
    channel,
    noteInfo,
    noteNumber,
    velocity,
    startTime,
    isSF3,
  ) {
    const bufferSource = await this.createNoteBufferNode(noteInfo, isSF3);
    const semitoneOffset = this.calcSemitoneOffset(channel);
    bufferSource.playbackRate.value = this.calcPlaybackRate(
      noteInfo,
      noteNumber,
      semitoneOffset,
    );

    // volume envelope
    const gainNode = new GainNode(this.audioContext, {
      gain: 0,
    });
    let volume = (velocity / 127) * channel.volume * channel.expression;
    if (volume === 0) volume = 1e-6; // exponentialRampToValueAtTime() requires a non-zero value
    const attackVolume = this.cbToRatio(-noteInfo.initialAttenuation) * volume;
    const sustainVolume = attackVolume * (1 - noteInfo.volSustain);
    const volDelay = startTime + noteInfo.volDelay;
    const volAttack = volDelay + noteInfo.volAttack;
    const volHold = volAttack + noteInfo.volHold;
    const volDecay = volHold + noteInfo.volDecay;
    gainNode.gain
      .setValueAtTime(1e-6, volDelay) // exponentialRampToValueAtTime() requires a non-zero value
      .exponentialRampToValueAtTime(attackVolume, volAttack)
      .setValueAtTime(attackVolume, volHold)
      .linearRampToValueAtTime(sustainVolume, volDecay);

    // filter envelope
    const softPedalFactor = 1 -
      (0.1 + (noteNumber / 127) * 0.2) * channel.softPedal;
    const maxFreq = this.audioContext.sampleRate / 2;
    const baseFreq = this.centToHz(noteInfo.initialFilterFc) * softPedalFactor;
    const peekFreq = this.centToHz(
      noteInfo.initialFilterFc + noteInfo.modEnvToFilterFc,
    ) * softPedalFactor;
    const sustainFreq = (baseFreq +
      (peekFreq - baseFreq) * (1 - noteInfo.modSustain)) * softPedalFactor;
    const adjustedBaseFreq = Math.min(maxFreq, baseFreq);
    const adjustedPeekFreq = Math.min(maxFreq, peekFreq);
    const adjustedSustainFreq = Math.min(maxFreq, sustainFreq);
    const filterNode = new BiquadFilterNode(this.audioContext, {
      type: "lowpass",
      Q: noteInfo.initialFilterQ / 10, // dB
      frequency: adjustedBaseFreq,
    });
    const modDelay = startTime + noteInfo.modDelay;
    const modAttack = modDelay + noteInfo.modAttack;
    const modHold = modAttack + noteInfo.modHold;
    const modDecay = modHold + noteInfo.modDecay;
    filterNode.frequency
      .setValueAtTime(adjustedBaseFreq, modDelay)
      .exponentialRampToValueAtTime(adjustedPeekFreq, modAttack)
      .setValueAtTime(adjustedPeekFreq, modHold)
      .linearRampToValueAtTime(adjustedSustainFreq, modDecay);

    let lfoGain;
    if (channel.modulation > 0) {
      const vibratoDelay = startTime + channel.vibratoDelay;
      const vibratoAttack = vibratoDelay + 0.1;
      lfoGain = new GainNode(this.audioContext, {
        gain: 0,
      });
      lfoGain.gain
        .setValueAtTime(1e-6, vibratoDelay) // exponentialRampToValueAtTime() requires a non-zero value
        .exponentialRampToValueAtTime(channel.modulation, vibratoAttack);
      channel.modulationEffect.lfo.connect(lfoGain);
      lfoGain.connect(bufferSource.detune);
    }

    bufferSource.connect(filterNode);
    filterNode.connect(gainNode);

    if (this.mono && channel.currentBufferSource) {
      channel.currentBufferSource.stop(startTime);
      channel.currentBufferSource = bufferSource;
    }
    bufferSource.start(startTime, noteInfo.start / noteInfo.sampleRate);
    return { bufferSource, gainNode, filterNode, lfoGain };
  }

  calcBank(channel, channelNumber) {
    if (channel.bankMSB === 121) {
      return 0;
    }
    if (channelNumber % 9 <= 1 && channel.bankMSB === 120) {
      return 128;
    }
    return channel.bank;
  }

  async scheduleNoteOn(channelNumber, noteNumber, velocity, startTime) {
    const channel = this.channels[channelNumber];
    const bankNumber = this.calcBank(channel, channelNumber);
    const soundFontIndex = this.soundFontTable[channel.program].get(bankNumber);
    if (soundFontIndex === undefined) return;
    const soundFont = this.soundFonts[soundFontIndex];
    const isSF3 = soundFont.parsed.info.version.major === 3;
    const noteInfo = soundFont.getInstrumentKey(
      bankNumber,
      channel.program,
      noteNumber,
    );
    if (!noteInfo) return;
    const { bufferSource, gainNode, filterNode, lfoGain } = await this
      .createNoteAudioChain(
        channel,
        noteInfo,
        noteNumber,
        velocity,
        startTime,
        isSF3,
      );
    this.connectNoteEffects(channel, gainNode);

    if (channel.sostenutoPedal) {
      channel.sostenutoNotes.set(noteNumber, {
        gainNode,
        filterNode,
        bufferSource,
        noteNumber,
        noteInfo,
      });
    }
    const scheduledNotes = channel.scheduledNotes;
    const scheduledNote = {
      bufferSource,
      filterNode,
      gainNode,
      lfoGain,
      noteInfo,
      noteNumber,
      startTime,
    };
    if (scheduledNotes.has(noteNumber)) {
      scheduledNotes.get(noteNumber).push(scheduledNote);
    } else {
      scheduledNotes.set(noteNumber, [scheduledNote]);
    }
  }

  noteOn(channelNumber, noteNumber, velocity) {
    const now = this.audioContext.currentTime;
    return this.scheduleNoteOn(channelNumber, noteNumber, velocity, now);
  }

  scheduleNoteRelease(
    channelNumber,
    noteNumber,
    velocity,
    stopTime,
    stopPedal = false,
  ) {
    const channel = this.channels[channelNumber];
    if (stopPedal && channel.sustainPedal) return;
    if (stopPedal && channel.sostenutoNotes.has(noteNumber)) return;
    if (!channel.scheduledNotes.has(noteNumber)) return;
    const targetNotes = channel.scheduledNotes.get(noteNumber);
    for (let i = 0; i < targetNotes.length; i++) {
      const targetNote = targetNotes[i];
      if (!targetNote) continue;
      if (targetNote.ending) continue;
      const { bufferSource, filterNode, gainNode, lfoGain, noteInfo } =
        targetNote;
      const velocityRate = (velocity + 127) / 127;
      const volEndTime = stopTime + noteInfo.volRelease * velocityRate;
      gainNode.gain.cancelScheduledValues(stopTime);
      gainNode.gain.linearRampToValueAtTime(0, volEndTime);
      const maxFreq = this.audioContext.sampleRate / 2;
      const baseFreq = this.centToHz(noteInfo.initialFilterFc);
      const adjustedBaseFreq = Math.min(maxFreq, baseFreq);
      const modEndTime = stopTime + noteInfo.modRelease * velocityRate;
      filterNode.frequency
        .cancelScheduledValues(stopTime)
        .linearRampToValueAtTime(adjustedBaseFreq, modEndTime);
      targetNote.ending = true;
      this.scheduleTask(() => {
        bufferSource.loop = false;
      }, stopTime);
      return new Promise((resolve) => {
        bufferSource.onended = () => {
          targetNotes[i] = null;
          bufferSource.disconnect(0);
          filterNode.disconnect(0);
          gainNode.disconnect(0);
          if (lfoGain) lfoGain.disconnect(0);
          resolve();
        };
        bufferSource.stop(volEndTime);
      });
    }
  }

  releaseNote(channelNumber, noteNumber, velocity) {
    const now = this.audioContext.currentTime;
    return this.scheduleNoteRelease(channelNumber, noteNumber, velocity, now);
  }

  releaseSustainPedal(channelNumber, halfVelocity) {
    const velocity = halfVelocity * 2;
    const channel = this.channels[channelNumber];
    const promises = [];
    channel.sustainPedal = false;
    channel.scheduledNotes.forEach((scheduledNotes) => {
      scheduledNotes.forEach((scheduledNote) => {
        if (scheduledNote) {
          const { noteNumber } = scheduledNote;
          const promise = this.releaseNote(channelNumber, noteNumber, velocity);
          promises.push(promise);
        }
      });
    });
    return promises;
  }

  releaseSostenutoPedal(channelNumber, halfVelocity) {
    const velocity = halfVelocity * 2;
    const channel = this.channels[channelNumber];
    const promises = [];
    channel.sostenutoPedal = false;
    channel.sostenutoNotes.forEach((activeNote) => {
      const { noteNumber } = activeNote;
      const promise = this.releaseNote(channelNumber, noteNumber, velocity);
      promises.push(promise);
    });
    channel.sostenutoNotes.clear();
    return promises;
  }

  handleMIDIMessage(statusByte, data1, data2) {
    const channelNumber = omni ? 0 : statusByte & 0x0F;
    const messageType = statusByte & 0xF0;
    switch (messageType) {
      case 0x80:
        return this.releaseNote(channelNumber, data1, data2);
      case 0x90:
        return this.noteOn(channelNumber, data1, data2);
      case 0xA0:
        return; // this.handlePolyphonicKeyPressure(channelNumber, data1, data2);
      case 0xB0:
        return this.handleControlChange(channelNumber, data1, data2);
      case 0xC0:
        return this.handleProgramChange(channelNumber, data1);
      case 0xD0:
        return this.handleChannelPressure(channelNumber, data1);
      case 0xE0:
        return this.handlePitchBendMessage(channelNumber, data1, data2);
      default:
        console.warn(`Unsupported MIDI message: ${messageType.toString(16)}`);
    }
  }

  handlePolyphonicKeyPressure(channelNumber, noteNumber, pressure) {
    const now = this.audioContext.currentTime;
    const channel = this.channels[channelNumber];
    pressure /= 64;
    const activeNotes = this.getActiveNotes(channel);
    if (channel.polyphonicKeyPressure.amplitudeControl !== 1) {
      if (activeNotes.has(noteNumber)) {
        const activeNote = activeNotes.get(noteNumber);
        const gain = activeNote.gainNode.gain.value;
        activeNote.gainNode.gain
          .cancelScheduledValues(now)
          .setValueAtTime(gain * pressure, now);
      }
    }
  }

  handleProgramChange(channelNumber, program) {
    const channel = this.channels[channelNumber];
    channel.bank = channel.bankMSB * 128 + channel.bankLSB;
    channel.program = program;
  }

  handleChannelPressure(channelNumber, pressure) {
    const now = this.audioContext.currentTime;
    const channel = this.channels[channelNumber];
    pressure /= 64;
    channel.channelPressure = pressure;
    const activeNotes = this.getActiveNotes(channel);
    if (channel.channelPressure.amplitudeControl !== 1) {
      activeNotes.forEach((activeNote) => {
        const gain = activeNote.gainNode.gain.value;
        activeNote.gainNode.gain
          .cancelScheduledValues(now)
          .setValueAtTime(gain * pressure, now);
      });
    }
  }

  handlePitchBendMessage(channelNumber, lsb, msb) {
    const pitchBend = msb * 128 + lsb;
    this.handlePitchBend(channelNumber, pitchBend);
  }

  handlePitchBend(channelNumber, pitchBend) {
    const now = this.audioContext.currentTime;
    const channel = this.channels[channelNumber];
    channel.pitchBend = (pitchBend - 8192) / 8192;
    const semitoneOffset = this.calcSemitoneOffset(channel);
    const activeNotes = this.getActiveNotes(channel);
    activeNotes.forEach((activeNote) => {
      const { bufferSource, noteInfo, noteNumber } = activeNote;
      const playbackRate = calcPlaybackRate(
        noteInfo,
        noteNumber,
        semitoneOffset,
      );
      bufferSource.playbackRate
        .cancelScheduledValues(now)
        .setValueAtTime(playbackRate * pressure, now);
    });
  }

  handleControlChange(channelNumber, controller, value) {
    switch (controller) {
      case 0:
        return this.setBankMSB(channelNumber, value);
      case 1:
        return this.setModulation(channelNumber, value);
      case 5:
        return this.setPortamentoTime(channelNumber, value);
      case 6:
        return this.setDataEntry(channelNumber, value, true);
      case 7:
        return this.setVolume(channelNumber, value);
      case 10:
        return this.setPan(channelNumber, value);
      case 11:
        return this.setExpression(channelNumber, value);
      case 32:
        return this.setBankLSB(channelNumber, value);
      case 38:
        return this.setDataEntry(channelNumber, value, false);
      case 64:
        return this.setSustainPedal(channelNumber, value);
      case 65:
        return this.setPortamento(channelNumber, value);
      case 66:
        return this.setSostenutoPedal(channelNumber, value);
      case 67:
        return this.setSoftPedal(channelNumber, value);
      // TODO: 71-75
      case 76:
        return this.setVibratoRate(channelNumber, value);
      case 77:
        return this.setVibratoDepth(channelNumber, value);
      case 78:
        return this.setVibratoDelay(channelNumber, value);
      case 91:
        return this.setReverb(channelNumber, value);
      case 93:
        return this.setChorus(channelNumber, value);
      case 96:
        return incrementRPNValue(channelNumber);
      case 97:
        return decrementRPNValue(channelNumber);
      case 100:
        return this.setRPNMSB(channelNumber, value);
      case 101:
        return this.setRPNLSB(channelNumber, value);
      case 120:
        return this.allSoundOff(channelNumber);
      case 121:
        return this.resetAllControllers(channelNumber);
      case 123:
        return this.allNotesOff(channelNumber);
      case 124:
        return this.omniOff();
      case 125:
        return this.omniOn();
      case 126:
        return this.monoOn();
      case 127:
        return this.polyOn();
      default:
        console.warn(
          `Unsupported Control change: controller=${controller} value=${value}`,
        );
    }
  }

  setBankMSB(channelNumber, msb) {
    this.channels[channelNumber].bankMSB = msb;
  }

  setModulation(channelNumber, modulation) {
    const channel = this.channels[channelNumber];
    channel.modulation = (modulation / 127) *
      (channel.modulationDepthRange * 100);
  }

  setPortamentoTime(channelNumber, portamentoTime) {
    this.channels[channelNumber].portamentoTime = portamentoTime / 127;
  }

  setVolume(channelNumber, volume) {
    const channel = this.channels[channelNumber];
    channel.volume = volume / 127;
    this.updateChannelGain(channel);
  }

  setPan(channelNumber, pan) {
    const now = this.audioContext.currentTime;
    const channel = this.channels[channelNumber];
    channel.pan = pan / 127 * 2 - 1; // -1 (left) - +1 (right)
    channel.pannerNode.pan.cancelScheduledValues(now);
    channel.pannerNode.pan.setValueAtTime(channel.pan, now);
  }

  setExpression(channelNumber, expression) {
    const channel = this.channels[channelNumber];
    channel.expression = expression / 127;
    this.updateChannelGain(channel);
  }

  setBankLSB(channelNumber, lsb) {
    this.channels[channelNumber].bankLSB = lsb;
  }

  updateChannelGain(channel) {
    const now = this.audioContext.currentTime;
    const volume = channel.volume * channel.expression;
    channel.gainNode.gain.cancelScheduledValues(now);
    channel.gainNode.gain.setValueAtTime(volume, now);
  }

  setSustainPedal(channelNumber, value) {
    const isOn = value >= 64;
    this.channels[channelNumber].sustainPedal = isOn;
    if (!isOn) {
      this.releaseSustainPedal(channelNumber, value);
    }
  }

  setPortamento(channelNumber, value) {
    this.channels[channelNumber].portamento = value >= 64;
  }

  setReverb(channelNumber, reverb) {
    const now = this.audioContext.currentTime;
    const channel = this.channels[channelNumber];
    const reverbEffect = channel.reverbEffect;
    channel.reverb = reverb / 127 * this.reverbFactor;
    reverbEffect.dryGain.gain.cancelScheduledValues(now);
    reverbEffect.dryGain.gain.setValueAtTime(1 - channel.reverb, now);
    reverbEffect.wetGain.gain.cancelScheduledValues(now);
    reverbEffect.wetGain.gain.setValueAtTime(channel.reverb, now);
  }

  setChorus(channelNumber, chorus) {
    const channel = this.channels[channelNumber];
    channel.chorus = chorus / 127;
    channel.chorusEffect.lfoGain = channel.chorus;
  }

  setSostenutoPedal(channelNumber, value) {
    const isOn = value >= 64;
    const channel = this.channels[channelNumber];
    channel.sostenutoPedal = isOn;
    if (isOn) {
      const activeNotes = this.getActiveNotes(channel);
      channel.sostenutoNotes = new Map(activeNotes);
    } else {
      this.releaseSostenutoPedal(channelNumber, value);
    }
  }

  setSoftPedal(channelNumber, softPedal) {
    const channel = this.channels[channelNumber];
    channel.softPedal = softPedal / 127;
  }

  setVibratoRate(channelNumber, vibratoRate) {
    const now = this.audioContext.currentTime;
    const channel = this.channels[channelNumber];
    channel.vibratoRate = vibratoRate / 127 * 4 + 3; // 3-7Hz
    channel.modulationEffect.lfo.frequency
      .cancelScheduledValues(now)
      .setValueAtTime(channel.vibratoRate, now);
  }

  setVibratoDepth(channelNumber, vibratoDepth) {
    const now = this.audioContext.currentTime;
    const channel = this.channels[channelNumber];
    channel.vibratoDepth = vibratoDepth / 127;
    channel.modulationEffect.lfoGain.gain
      .cancelScheduledValues(now)
      .setValueAtTime(channel.vibratoDepth, now);
  }

  setVibratoDelay(channelNumber, vibratoDelay) {
    // Access Virus: 0-10sec
    // Elektron: 0-5sec
    // Korg: 0-5sec
    // Nord: 0-5sec
    // Roland: 0-5sec
    // Yamaha: 0-8sec
    const channel = this.channels[channelNumber];
    channel.vibratoDelay = vibratoDelay / 127 * 5; // 0-5sec
  }

  incrementRPNValue(channelNumber) {
    const channel = this.channels[channelNumber];
    const rpn = channel.rpnMSB * 128 + channel.rpnLSB;
    switch (rpn) {
      case 0:
        channel.pitchBendRange = Math.min(1, channel.pitchBendRange + 1);
        break;
      case 1:
        channel.fineTuning = Math.min(1, channel.fineTuning + 1);
        break;
      case 2:
        channel.coarseTuning = Math.min(88, channel.coarseTuning + 1);
        break;
      default:
        console.warn(
          `Channel ${channelNumber}: Unsupported RPN MSB=${channel.rpnMSB} LSB=${channel.rpnLSB}`,
        );
    }
  }

  decrementRPNValue(channelNumber) {
    const channel = this.channels[channelNumber];
    const rpn = channel.rpnMSB * 128 + channel.rpnLSB;
    switch (rpn) {
      case 0:
        channel.pitchBendRange = Math.max(-1, channel.pitchBendRange - 1);
        break;
      case 1:
        channel.fineTuning = Math.max(-1, channel.fineTuning - 1);
        break;
      case 2:
        channel.coarseTuning = Math.max(40, channel.coarseTuning - 1);
        break;
      default:
        console.warn(
          `Channel ${channelNumber}: Unsupported RPN MSB=${channel.rpnMSB}, LSB=${channel.rpnLSB}.`,
        );
    }
  }

  setRPNMSB(channelNumber, value) {
    this.channels[channelNumber].rpnMSB = value;
  }

  setRPNLSB(channelNumber, value) {
    this.channels[channelNumber].rpnLSB = value;
  }

  // TODO: support 3-4?
  setDataEntry(channelNumber, value, isMSB) {
    const channel = this.channels[channelNumber];
    const rpn = channel.rpnMSB * 128 + channel.rpnLSB;
    isMSB ? channel.dataMSB = value : channel.dataLSB = value;
    const { dataMSB, dataLSB } = channel;
    switch (rpn) {
      case 0:
        channel.pitchBendRange = dataMSB + dataLSB / 100;
        break;
      case 1:
        channel.fineTuning = (dataMSB * 128 + dataLSB - 8192) / 8192;
        break;
      case 2:
        channel.coarseTuning = dataMSB - 64;
        break;
      case 5:
        channel.modulationDepthRange = dataMSB + dataLSB / 128;
        break;
      default:
        console.warn(
          `Channel ${channelNumber}: Unsupported RPN MSB=${channel.rpnMSB} LSB=${channel.rpnLSB}`,
        );
    }
  }

  allSoundOff(channelNumber) {
    const now = this.audioContext.currentTime;
    const channel = this.channels[channelNumber];
    const velocity = 0;
    const stopPedal = true;
    const promises = [];
    channel.scheduledNotes.forEach((scheduledNotes) => {
      const activeNote = this.getActiveChannelNotes(scheduledNotes);
      if (activeNote) {
        const notePromise = this.scheduleNoteRelease(
          channelNumber,
          noteNumber,
          velocity,
          now,
          stopPedal,
        );
        promises.push(notePromise);
      }
    });
    return promises;
  }

  resetAllControllers(channelNumber) {
    Object.assign(this.channels[channelNumber], this.effectSettings);
  }

  allNotesOff(channelNumber) {
    const now = this.audioContext.currentTime;
    const channel = this.channels[channelNumber];
    const velocity = 0;
    const stopPedal = false;
    const promises = [];
    channel.scheduledNotes.forEach((scheduledNotes) => {
      const activeNote = this.getActiveChannelNotes(scheduledNotes);
      if (activeNote) {
        const notePromise = this.scheduleNoteRelease(
          channelNumber,
          noteNumber,
          velocity,
          now,
          stopPedal,
        );
        promises.push(notePromise);
      }
    });
    return promises;
  }

  omniOff() {
    this.omni = false;
  }

  omniOn() {
    this.omni = true;
  }

  monoOn() {
    this.mono = true;
  }

  polyOn() {
    this.mono = false;
  }

  handleUniversalNonRealTimeExclusiveMessage(data) {
    switch (data[2]) {
      case 9:
        switch (data[3]) {
          case 1:
            this.GM1SystemOn();
            break;
          case 2: // GM System Off
            break;
          case 3:
            this.GM2SystemOn();
            break;
          default:
            console.warn(`Unsupported Exclusive Message ${data}`);
        }
        break;
      default:
        console.warn(`Unsupported Exclusive Message ${data}`);
    }
  }

  GM1SystemOn() {
    this.channels.forEach((channel) => {
      channel.bankMSB = 0;
      channel.bankLSB = 0;
      channel.bank = 0;
    });
    this.channels[9].bankMSB = 120;
    this.channels[9].bank = 120 * 128;
  }

  GM2SystemOn() {
    this.channels.forEach((channel) => {
      channel.bankMSB = 121;
      channel.bankLSB = 0;
      channel.bank = 121 * 128;
    });
    this.channels[9].bankMSB = 120;
    this.channels[9].bank = 120 * 128;
  }

  handleUniversalRealTimeExclusiveMessage(data) {
    switch (data[2]) {
      case 4:
        switch (data[3]) {
          case 1:
            return this.handleMasterVolumeSysEx(data);
          case 3:
            return this.handleMasterFineTuning(data);
          case 4:
            return this.handleMasterCoarseTuning(data);
          // case 5: // TODO: Global Parameter Control
          default:
            console.warn(`Unsupported Exclusive Message ${data}`);
        }
        break;
      case 8:
        switch (data[3]) {
          // case 8:
          //   // TODO
          //   return this.handleScaleOctaveTuning1ByteFormat();
          default:
            console.warn(`Unsupported Exclusive Message ${data}`);
        }
        break;
      case 9:
        switch (data[3]) {
          // case 1:
          //   // TODO
          //   return this.setChannelPressure();
          // case 3:
          //   // TODO
          //   return this.setControlChange();
          default:
            console.warn(`Unsupported Exclusive Message ${data}`);
        }
        break;
      case 10:
        switch (data[3]) {
          // case 1:
          //   // TODO
          //   return this.handleKeyBasedInstrumentControl();
          default:
            console.warn(`Unsupported Exclusive Message ${data}`);
        }
        break;
      default:
        console.warn(`Unsupported Exclusive Message ${data}`);
    }
  }

  handleMasterVolumeSysEx(data) {
    const volume = (data[5] * 128 + data[4]) / 16383;
    this.handleMasterVolume(volume);
  }

  handleMasterVolume(volume) {
    if (volume < 0 && 1 < volume) {
      console.error("Master Volume is out of range");
    } else {
      const now = this.audioContext.currentTime;
      this.masterGain.gain.cancelScheduledValues(now);
      this.masterGain.gain.setValueAtTime(volume * volume, now);
    }
  }

  handleMasterFineTuningSysEx(data) {
    const fineTuning = (data[5] * 128 + data[4] - 8192) / 8192;
    this.handleMasterFineTuning(fineTuning);
  }

  handleMasterFineTuning(fineTuning) {
    if (fineTuning < -1 && 1 < fineTuning) {
      console.error("Master Fine Tuning value is out of range");
    } else {
      this.masterFineTuning = fineTuning;
    }
  }

  handleMasterCoarseTuningSysEx(data) {
    const coarseTuning = data[4];
    this.handleMasterCoarseTuning(coarseTuning);
  }

  handleMasterCoarseTuning(coarseTuning) {
    if (coarseTuning < 0 && 127 < coarseTuning) {
      console.error("Master Coarse Tuning value is out of range");
    } else {
      this.masterCoarseTuning = coarseTuning - 64;
    }
  }

  handleExclusiveMessage(data) {
    console.warn(`Unsupported Exclusive Message ${data}`);
  }

  handleSysEx(data) {
    switch (data[0]) {
      case 126:
        return this.handleUniversalNonRealTimeExclusiveMessage(data);
      case 127:
        return this.handleUniversalRealTimeExclusiveMessage(data);
      default:
        return this.handleExclusiveMessage(data);
    }
  }

  scheduleTask(callback, startTime) {
    return new Promise((resolve) => {
      const bufferSource = new AudioBufferSourceNode(this.audioContext);
      bufferSource.onended = () => {
        callback();
        resolve();
      };
      bufferSource.start(startTime);
      bufferSource.stop(startTime);
    });
  }
}
